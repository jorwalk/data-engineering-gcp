Why are we talking about this in the first place? Why are we talking about migration to the Cloud and products that help you do migration? To do that, it's probably good to look at this, a little, from a historical perspective. The first product, the first cloud product that Google had was App Engine. And the way App Engine worked was, you would develop a web application, write it in Java, upload this application to App Engine, and that was it. App Engine would, essentially, scale your code and server to users. If you have 20 users it may run it on one machine. And as the number of users ramped up, maybe at lunchtime you had 200 users, it'd automatically scale out to three machines. And then at one point your app goes viral, you have millions of users, no problem. App Engines just scales. So in 2008, Google was already doing a server-less, fully managed web application framework. So, this is great, but people found it very hard to get started, why? 

Well, because we required people to write their code in Java and that was it. We required that you use the App Engine framework. And people said, well, no, I have web applications already, I write them in Tomcat, what do you mean I cant' run Tomcat in App Engine? Or people would say, well I would rather write things in PHP, thank you very much, and App Engine was a no-go at that point.

It took us a while to basically recognize this issue. That while a Google engineer was perfectly happy to give up control and say well take care of this for me. Here's my code, just run it, scale it, deploy it, manage it. I'm quite happy to just write the code and have the service take care of all of the auto scaling and reliability considerations. This was not where the rest of the industry was. And so, this is what Eric Smith, who's the executive chairman of the board at Google. This is what he was referring to, when he said that there was something fundamentally wrong with what we were doing in 2008. He's talking about App Engine here. And what was wrong? What was wrong was that we didn't get the right stepping stones into the cloud. We weren't meeting our customers where they were. We were, instead, giving them a solution and saying look, this is what we use, come use it too. And, that works for people who have greenfield development needs. They don't have any legacy systems. They don't have systems that already work. They just want to have them continue working. That's good for start-up companies, starting new. So, we do have very large customers like, for example, Snapchat uses App Engine. It's one of the largest web traffic companies in the world and they essentially run completely on App Engine. And that allows them to basically get all kinds of scaling. Any issues just call Google, Google fixes it, that's great.

However, if you're not a new companies, doing greenfield development, there was no way to get onto App Engine. There was no nice, easy ramp up. And so, that's what Eric Schmidt was talking about when he said that we are doing something fundamentally wrong in 2008 that we need to fix. And we're fixing it now. So, the idea is that initially, we would just have your code, Java code. It would basically run in App Engine, and that was all you needed. And App Engine would provide all of the infrastructure. But now, we basically give you Google App Engine, which lets you run things that are not Java. So, you can run in a flex environment, you can run Python Flask apps, you can use other web frameworks. It's still your code, it's still going to get auto scaled. It's still going to, basically, take advantage of all of the capabilities that App Engine provides. But you get a lot more flexibility in terms of, taking code that you already have, and running it in App Engine. But let's say you don't have a web application, you actually want to take the application that you have and not run it in App Engine. You want to run it as is in, Tomcat. Well, containerize it and put it into a dock or container. And we will basically orchestrate those containers and manage them for you with Google Container Engine.

You don't want to even containerize it. It's running on bare metal, on-premise, and you'd like to move it to the cloud, and have it continue running in bare metal? No problem, we'll give you Compute Engine. And the idea behind Compute Engine is, you take your workload and you just have it run as is, on the cloud. So these are all of the stepping stones to take something, like a web application. Ideally, we hope that over time, you will

not have need to run all of this core infrastructure yourself. And instead allow Google Cloud to manage those infrastructure needs for you, so that you can concentrate on your business needs. But, we give you the stepping stones so that, over time, you can do this migration on your own schedule, rather than it being all or nothing.

And what is true of App Engine is also true of everything else. So, when we look at the Google Cloud, you have all of these hexagons. Because in many cases, these are different entry points into the cloud. Such that, if you're running a certain type of database on-premise and you want to move those workloads to the cloud, we want to give you an opportunity to do that. And that's essentially what many of these hexagons are about. So, when you are looking at running things on Google Cloud, part of it might be simply taking the same workload that you have, and simply changing where you do the computation. And the reason that we are not going to change the where is because Cloud can be cheaper. Cloud can be a little more secure, and that's basically what you want.

But on the other hand, there could be other instances where the reason that you're moving to the cloud is because you want additional scale and additional reliability.

Maybe you want very reliable large scale messaging and you're very interested then in Cloud Pub/Sub, which is a serverless. You don't have to actually even launch a server to get a message system going. A messaging service that you can, basically, publish to and subscribe to without actually having a cluster of POP subservers running, for example.

Similarly, you have needs around scalable, reliable data processing, data flow, dataproc. Those are all different ways to do that. But the idea is that these are all stepping stones to the transformation the cloud can provide. And that’s where we get to the changing how you do your computation. In terms of data expiration, in terms of business intelligence, in terms of machine learning, and all of those kinds of things. So, for example, for data warehousing, we believe that Google BigQuery is probably the best solution for a whole host of companies But you may not be ready to move into a so completely serverless, fully managed data warehouse solution yet. And so, a stepping stone to that could be, take the workloads that you have. And run them on Cloud Dataproc. And over time, maybe migrate some of your data sets, some of your workloads into BigQuery so you can forget about the infrastructure management that you're probably doing today. So the idea behind this module is to talk about those migrations.

The other thing that we want to talk about, and this is something that's throughout this course, is this transformation that's happening in our industry around machine learning. So this is Eric Schmidt again, the Executive Chairman of the Board at Google. In many ways he's a visionary, the person who says this is where we're headed and the whole company heads that way. So this is Eric Schmidt a couple of years ago, talking about machine learning. And he says, machine learning is the next transformation.

It's the new thing that we're going to be doing. And what's new about it? Well, the thing that you're changing is a programming paradigm. Instead of you programming a computer, Eric says, you're going to teach a computer to do something. And it's going to do what you want.

Notice here that the way Eric's talking about machine learning is that he's not talking about it from the point of view of data. We know that machine learning is about learning from data. So data is very important, but Eric is actually having us think a little bit more about machine learning and saying this is about logic. It's about replacing the way you do things and, of course, wired saw this and the headline is, soon we won't program computers, we'll train them like dogs.

But that kind of gets at the point that Eric Schmidt's also making. The way that dogs learn is not in terms of rules saying do this, do this, do this, if this do that. But instead by being exposed to a number of scenarios and figuring out what's correct and what's incorrect behavior in those scenarios. And over time, the dog learns, and the idea is that over time our computer programs can also learn. Now, machine learning has been around for a very long time. Neural networks have been around since the 70s, for example.

But I think machine learning basically came into people's consciousness, only with recommendation engines. This is where you go to an e-commerce site and then you basically see a message that says, people who bought this also bought this. Or you may have gone to a music service and the music service is basically giving you a playing list of songs that you might like.

Daily song list. That's kind of personally curated for you, except that it cannot have been really personally curated by a person, because that doesn't scale. Instead, it's that computer algorithm that's somehow figuring out the kind of songs that you would like and putting together a playlist for you. Or movies, where you basically get movie recommendations. So what's a recommendation engine? It's all of these kinds of things where it says, you would like this product because you've liked products like this in the past. So who uses them? E-commerce sites, movie sites, etc. So the example that we're going to pick up is that we're going to try to basically talk about rental houses and say as our example that we want to be able to recommend to people. Here are some houses for you to go look at.

So if somebody's hunting around for houses and we would recommend houses to them.

So how would they work? How do recommendation agents work?

The way it works often is that you start with ratings. So either explicitly or implicitly, users go through a catalog and over time they've rated some houses. So you could rate a house with actually going and visiting the house. A user comes back and says that was not a house they liked. I’m going to give that a two or a five. And they give you a rating over time, that you've got ratings from that user for a few houses and you can use that as part of your training dataset. But you could also have implicit ratings, and implicit ratings could be the user clicked on a link for that house. That basically indicates that they are interested in the house. Or if you have a mobile app, you can actually look at how long somebody looked at the house before they scrolled past it. So that could be part of the rating. So you could have explicit ratings in the form of stars or implicit ratings in the form of links or time that you've looked at it, etc. So you have those ratings. The thing to realize is, how many of the products actually get rated? So let's say you have a catalog of 10,000 houses. How many of those houses per individual user have rated?

Maybe five, maybe ten. That's pretty much it.

So it's from these ratings. So let's say every user has rated 5 houses. If we have a million users, and we have 100,000 objects, we essentially have a matrix that's got 1 million rows and 100,000 columns. And that matrix is extremely sparse because every user has rated only maybe 5 or 10 of those items and the remaining 995 objects are unrated. But we need to come up with the rating for each of them. So that's basically what the ML model needs to do. It needs to predict what a user would rate a house that they haven't yet visited.

In order to do that, we need to build a ML model.

But let's say we have that machine learning module that can basically say, this house the user would rate it 2.1, this house they would rate it 3.4, this house they may rate it 1.7, etc., etc. Essentially the recommended part of it is simply to go through that catalog of 100,000 houses. Take for every user, and then take the ratings, find the top five ratings and basically suggest those to them. That's essentially all they're recommending. Their recommending is a very cheap operation, it's just a sort find the top five, return the top five. The interesting thing is how you build the ML model. So how would you build this model to predict the rating of a house for a user?

Intuitively, we kind of know how this ought to work.

We will basically say that if we have two users that happen to have rated house A, the same, because they happened to have visited and the first user rates it a four, second user also rates it a four. We could kind of say intuitively that let's go to the first user, find out all the other houses that they rated, and say these two guys now if they rated this house both a four, maybe they will share the rating for everything else. So in other words, you could basically say who is this user like. So go through all of those users for those houses and say, has this user rated the same house as somebody else, and let's kind of propagate that rating that way. Remember the whole idea is to fill out the metrics of every user, let's say a million users, and every item, let's say 100,000 items. So this 1 million by 100,000 matrix needs to get filled out. And could get filled out starting by looking at whether two rows, which each row corresponds to a user, are not similar to each other. The other way that you can do this is to look at the houses themselves, and seek popular houses will tend to be like. Unpopular houses will tend not to be like. So you might have a house that everyone who's looked at has agreed that it's a dump. They're basically rating it one or two out of five.

You could kind of, from that infer that everyone is going to rate it at one or two. It's a dump. The house is a bad house, everyone's going to rate it badly. So in the absence of other information about a particular user, and the kinds of things that they like, go with the majority vote, and that's the second way that you do it. So essentially we need to cluster users, we need to cluster items, and combine the two of them to produce a rating.

So how often do we need to compute this predictive rating? Remember that computing the predicted rating is filling out that huge matrix. It takes a long time. It may take hours. But when do you need to recompute the rating?

You will need to recompute the rating whenever the user comes in and rates a new house, or something else happens. Maybe some other user rates a house that causes your rating to change. Now this is not a very common occurrence. It's not something that you may have to do up to the minute. So this is the kind of thing that many people do as a batch job. They may say well, I'm going to do this once a week. Based on all the ratings that I have, I'm going to create my new recommendation model. And that is the recommendation model that I'm going to basically use for doing product recommendations.

And because this is the batch job run occasionally, a good place to run it would be Hadoop. So we will look at running this using PySpark, that's Spark in Python, on a Hadoop cluster. Which on GCP, the Hadoop cluster is called Dataproc. So we're going to use the Dataproc cluster to run a Python Spark job. And that's how we're going to compute the predicted rating.

The second part of the question is where do you see the results?

And if you're going to talk about where to save it, let's think about what to save. What are we saving?

What we're saving are the top five houses for every user. So if you have a million users, you have five houses per user, that's 5 million houses. This is small data. So this is the kind of thing that you could store in a relational database. It's transactional, because every day you may want to keep updating these recommendations. So you might want to do it in the context of a transaction for example and so a relation database makes perfect sense. So the second part of this use case is to store our results in a MySQL database. And the way you do a MySQL database in Google Cloud is to use Cloud SQL. It's a managed MySQL offering. So in order to solve this recommendation problem, we're going to look at MySQL on Cloud SQL, and we're going to look at Python Spark on Dataproc.
